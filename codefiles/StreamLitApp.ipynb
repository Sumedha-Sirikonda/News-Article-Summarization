{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"StreamLitApp.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyMzuF7kWcZe3wSnlKNayV0e"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"aL1uqBwDkKx1"},"source":["!pip install -q streamlit"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install -q transformers==4.5.0\n","# !pip install -q transformers==2.8.0\n","!pip install -q pytorch-lightning==1.2.7"],"metadata":{"id":"PRW4vZqBpEe3"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H4n2wVHbgqAb","executionInfo":{"status":"ok","timestamp":1639713209527,"user_tz":300,"elapsed":16063,"user":{"displayName":"Sumedha Sirikonda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13604935234152853023"}},"outputId":"38e0daee-7da7-4784-e5f1-a4eab47ea9d8"},"source":["from google.colab import  drive\n","import os\n","drive.mount('/content/gdrive')\n","\n","DATA_PATH = 'gdrive/Shared drives/Text_Summarization_Project/'\n","# pickles_folder = os.listdir(DATA_PATH)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JsLJaZxKsgHf","executionInfo":{"status":"ok","timestamp":1639713212968,"user_tz":300,"elapsed":182,"user":{"displayName":"Sumedha Sirikonda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13604935234152853023"}},"outputId":"2b56d01c-e012-431c-b99e-28ca7889fd56"},"source":["%cd /content/$DATA_PATH"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/Shared drives/Text_Summarization_Project\n"]}]},{"cell_type":"code","source":["pwd"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"W6RBGhndMFd0","executionInfo":{"status":"ok","timestamp":1639713214021,"user_tz":300,"elapsed":181,"user":{"displayName":"Sumedha Sirikonda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13604935234152853023"}},"outputId":"e29b2c8c-f39f-41c9-c34b-dd7e4c8992e3"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/gdrive/Shared drives/Text_Summarization_Project'"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["%%writefile meta.py\n","SUMMARY_STORY = \"\"\"\n","<div class=\"story-box font-body\">\n","<h2> About us</h2>\n","<p>\n","Hello everyone ðŸ‘‹, I am a <strong>News Article Summarizer</strong>. I'm here to give a little background of me and how we work here.\n","I was made by a group of <strong>UMBC Data Science Students</strong> to train my two prodigy summarizers who are well known in the \n","Technology: <strong>T5 Transformer</strong> and <strong>BERT Transformer</strong>. \n","The whole team participated in my rigorous training regiment of, <a href=\"https://huggingface.co/flax-community/t5-recipe-generation\">T5 fine-tuning</a>, \n","to learn how to get <strong>ABSTRACTIVE</strong> news summaries from any kind of News Articles. The students have tried really hard, invested a lot of time and \n","almost gave up in the processing. But they were patient to pull themselves together and get this final product for you users.\n","I've never been more proud of my summarizers -- both can produce exceptional article summaries but I regard T5 as being <em>creative</em> while BERT is <em>meticulous</em>. \n","If you give each of them the same articles, they'll usually come up with different summaries. <br /><br />\n","At the start of the program the summarizers read news articles containing thousands of news texts of different varieties like 'Extractive','Abstractive' and 'Mixed' formats\n","which were human written. \n","The DataScience Students helped guide the learning process so that the summarizers could actually learn which articles work well together rather than just memorize and train\n","on everything. I trained my summarizers by asking them to generate a summary, for an article after giving them few sensible lines on the news piece. \n","</p>\n","<pre>\n","    [Inputs]\n","    {News Article*: A complete CNN/Inshorts or any news article}\n","     \n","    [Targets]\n","    {News Summary*: A summarized format of the Above Article}\n","</pre>\n","<p>\n","  <em>The Summarizers were initially trained on <a href=\"https://lil.nlp.cornell.edu/newsroom/index.html\"> Newsroom dataset</a>, the items the student trainers mostly\n","  concentrated were the Text, Summary and Format Variables for this training. </em>\n","</p>\n","<p>\n","In the span of a 4 weeks, my summarizers went from spitting out nonsense to creating masterpiece summaries. \n","Their learning rate was exceptionally high and each batch of recipes was better than the last. <br />\n","Let me give you some more explaination on my Summarizers here on.\n","</p>\n","</div>\n","\"\"\".strip()\n","\n","T5_STORY=\"\"\"\n","<div class=\"story-box font-body\">\n","<h1>T5 - TRANSFORMER </h1>\n","<img src='./images/t5.gif' alt='Image of T5 model'/>\n","<p>\n","The Text-to-Text Transfer Transformer or T5 is a type of Transformer that is capable of being trained on a variety of tasks \n","with a uniform architecture. It was created by Google AI and was published about in the paper â€œ<a href=\"https://arxiv.org/abs/1910.10683\">Exploring the Limits of Transfer \n","Learning with a Unified Text-to-Text Transformer</a>â€œ. Here, weâ€™ll take a look at T5 architecture, pretraining, finetuning â€” including\n","variations and the conclusions that can be derived from them. It effectively summarizes the above linked paper.\n","T5 is an encoder-decoder model and converts all NLP problems into a text-to-text format. \n","It is trained using teacher forcing. This means that for training, we always need an input sequence and a corresponding target sequence.\n","The input sequence is fed to the model using input_ids. The target sequence is shifted to the right, i.e., prepended by a start-sequence \n","token and fed to the decoder using the decoder_input_ids. In teacher-forcing style, the target sequence is then appended by the EOS token \n","and corresponds to the labels. The PAD token is hereby used as the start-sequence token. \n","T5 can be trained / fine-tuned both in a supervised and unsupervised fashion.\n","</p>\n","\n","</div>\n","\n","\"\"\".strip()\n","\n","BERT_STORY=\"\"\"\n","\n","<div class=\"story-box font-body\">\n","<h1>BERT - TRANSFORMER </h1>\n","\n","<p>\n","BERT (<a href=\"https://arxiv.org/pdf/1810.04805.pdf\">Bidirectional Encoder Representations from Transformers</a>) is a recent \n","paper published by researchers at Google AI Language. It has caused a stir in the Machine Learning community by presenting \n","state-of-the-art results in a wide variety of NLP tasks, including Question Answering (SQuAD v1.1), Natural Language Inference (MNLI),\n","and others.BERTâ€™s key technical innovation is applying the bidirectional training of Transformer, a popular attention model, \n","to language modelling. This is in contrast to previous efforts which looked at a text sequence either from left to right or \n","combined left-to-right and right-to-left training. The paperâ€™s results show that a language model which is bidirectionally \n","trained can have a deeper sense of language context and flow than single-direction language models. In the paper, \n","the researchers detail a novel technique named Masked LM (MLM) which allows bidirectional training in models in which it was previously impossible.\n","\n","BERT makes use of Transformer, an attention mechanism that learns contextual relations between words (or sub-words) in a text. \n","In its vanilla form, Transformer includes two separate mechanisms â€” an encoder that reads the text input and a decoder that produces a prediction for the task. \n","Since BERTâ€™s goal is to generate a language model, only the encoder mechanism is necessary. The detailed workings of Transformer are described in a paper by Google.\n","\n","Here we are adding a pictorial representation of how our model works.\n","<img src='./images/bert_abs.png' alt='Image of T5 model'/>\n","</p>\n","\n","</div>\n","\n","\"\"\".strip()\n","\n","REFS_STORY=\"\"\"\n","\n","<div class=\"story-box font-body\">\n","<h3>References: </h3>\n","<p>Adding some of the reference papers and articles details</p>\n","<a href=\"https://arxiv.org/pdf/1810.04805.pdf\"> BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding </a>\n","<a href=\"https://arxiv.org/abs/1910.10683\">Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer</a>\n","<a href=\"https://huggingface.co/docs/transformers/index\"> Hugging Face Documentation</a>\n","<a href=\"https://towardsdatascience.com/bert-explained-state-of-the-art-language-model-for-nlp-f8b21a9b6270\">BERT Explained: State of the art language model for NLP</a>\n","<a href=\"https://paperswithcode.com/paper/text-to-text-pre-training-for-data-to-text\">Text-to-Text Pre-Training for Data-to-Text Tasks</a>\n","<a href=\"https://machinelearningmastery.com/encoder-decoder-recurrent-neural-network-models-neural-machine-translation/\">Encoder-Decoder Recurrent Neural Network Models for Neural Machine Translation</a>\n","\n","</div>\n","\"\"\".strip()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"heKLUyVh_IK-","executionInfo":{"status":"ok","timestamp":1639713216155,"user_tz":300,"elapsed":1007,"user":{"displayName":"Sumedha Sirikonda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13604935234152853023"}},"outputId":"a3fd159c-dd9b-4a06-b9b4-9d21d3bdb7f6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting meta.py\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i0F-eaiN8Mir","executionInfo":{"status":"ok","timestamp":1639713217796,"user_tz":300,"elapsed":565,"user":{"displayName":"Sumedha Sirikonda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13604935234152853023"}},"outputId":"84f18ad3-604b-42a7-e769-166c1c3d5e0d"},"source":["%%writefile app.py\n","import streamlit as st\n","import pickle\n","import t5transformer as t5\n","import bert_utils as bert\n","# import bert_transformer as bert\n","import meta as m\n","# PAGE_CONFIG = {\"page_title\":\"StColab.io\",\"page_icon\":\":smiley:\",\"layout\":\"centered\"}\n","# st.beta_set_page_config(**PAGE_CONFIG)\n","def computations_here(text_data,model_type):\n","\t\"\"\"\n","\tDo your computations here\n","\t\"\"\"\n","\tx = t5.test_df.loc[t5.test_df['text']==text_data]\n","\tif model_type == \"T5-Transformer\":\n","\t\tmodel_summary = t5.summarizeText(text_data)\n","\telse:\n","\t\tmod = bert.load_model(pretrained=True, path=f\"./models/temp_encdec_weights.pth\")\n","\t\tmodel_summary = bert.summarise_articles(text_data, mod)\n","  \n","\treturn x['summary'].values,model_summary\n","\n","def main():\n","\tmodel = bert.load_model(pretrained=True, path=f\"./models/temp_encdec_weights.pth\")\n","\tst.title(\"News Summarization\")\n","\tmenu = [\"Home\",\"Demo_Article\",\"Custom_Article\",\"Final Notes\"]\n","\tchoice = st.sidebar.selectbox(\"Menu\",menu)\n","\tif choice == 'Home':\n","\t\tst.image('/content/gdrive/Shareddrives/Text_Summarization_Project/images/Text-Summarization-front.jpg')\n","\t\tst.markdown(m.SUMMARY_STORY,unsafe_allow_html=True)\n","\t\tst.markdown(m.T5_STORY,unsafe_allow_html=True)\n","  \t\tst.markdown(m.BERT_STORY,unsafe_allow_html=True)\n","\n","\telif choice == 'Demo_Article':\n","\t\tst.header(\" Input News Article \")\n","\t\tinput_val = \"Replace this text with News Article\"\n","\t\t# txt = st.text_area(\"Article :\",placeholder=input_val,height=350)\n","\t\ttxt = st.selectbox('Test Article to Summarize : ',options=t5.test_df['text'])\n","\t\tmodel = ['T5-Transformer','BERT-Classifier']\n","\t\tmodel_choice = st.selectbox('Model ',model)\n","\t\t# st.selectbox('Model to use:',model)\n","\t\tst.header(\" Output Summary \")\n","\t\tif st.button(\"Summarize Article\"):\n","\t\t\tif model_choice == \"T5-Transformer\":\n","\t\t\t\toriginal_summary, predicted_summary = computations_here(txt,model_choice)\n","\t\t\telif model_choice == \"BERT-Classifier\":\n","\t\t\t\tpredicted_summary=\"Summarizing with BERT-Classifier\"\n","\t\t\t\toriginal_summary = \"Summarizing with BERT-Classifier\"\n","\t\telse:\n","\t\t\tpredicted_summary = \"Generated Summary of the Article\"\n","\t\t\toriginal_summary = \"Generated Summary of the Article\"\n","\t\tst.text_area(\"Predicted Summary :\",predicted_summary,height=250)\n","\t\tst.text_area(\"Original Summary :\",original_summary,height=250)\n","\n","\telif choice == 'Custom_Article':\n","\t\tst.header(\" Input News Article \")\n","\t\tinput_val = \"Replace this text with News Article\"\n","\t\ttxt = st.text_area(\"Article :\",placeholder=input_val,height=350)\n","\t\tmodel = ['T5-Transformer','BERT-Transformer']\n","\t\tmodel_choice = st.selectbox('Model ',model)\n","\t\t# st.selectbox('Model to use:',model)\n","\t\tst.header(\" Output Summary \")\n","\t\t\n","\t\t# Add model details here\n","\t\tif st.button(\"Summarize Article\"):\n","\t\t\tif model_choice == \"T5-Transformer\":\n","\t\t\t\tsummary_val= t5.summarizeText(txt)\n","\t\t\telif model_choice == \"BERT-Transformer\":\n","\t\t\t\tsummary_val=bert.summarise_articles(txt, model)\n","\t\telse:\n","\t\t\tsummary_val = \"Generated Summary of the Article\"\n","\t\tst.text_area(\"Summary :\",summary_val,height=250)\n","\telif choice == 'Final Notes':\n","\t\tst.write('Link to access all the code and presentations on <a href=\"https://github.com/Sumedha-Sirikonda/News-Article-Summarization\">Github Repo</a>')\n","\t\tst.markdown(m.REFS_STORY,unsafe_allow_html=True)\n","\n","if __name__ == '__main__':\n","\tmain()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting app.py\n"]}]},{"cell_type":"code","metadata":{"id":"keQFur93_TGG"},"source":["# !streamlit run app.py \n","%%bash --bg\n","streamlit run /content/gdrive/Shareddrives/Text_Summarization_Project/app.py > debug.log 2>&1\n","# streamlit run /content/gdrive/Shareddrives/Text_Summarization_Project/app.py &>/dev/null&"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vudFOHebAo8S"},"source":["!tail debug.log"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V9ZAA1G__eAs","executionInfo":{"status":"ok","timestamp":1639713226639,"user_tz":300,"elapsed":2259,"user":{"displayName":"Sumedha Sirikonda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13604935234152853023"}},"outputId":"276defec-0e52-4288-d162-84a3e5cd261e"},"source":["!curl http://172.28.0.2:8501"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<!doctype html><html lang=\"en\"><head><meta charset=\"UTF-8\"/><meta name=\"viewport\" content=\"width=device-width,initial-scale=1,shrink-to-fit=no\"/><link rel=\"shortcut icon\" href=\"./favicon.png\"/><title>Streamlit</title><script src=\"./vendor/viz/viz-1.8.0.min.js\" type=\"javascript/worker\"></script><script src=\"./vendor/bokeh/bokeh-2.4.1.min.js\"></script><script src=\"./vendor/bokeh/bokeh-widgets-2.4.1.min.js\"></script><script src=\"./vendor/bokeh/bokeh-tables-2.4.1.min.js\"></script><script src=\"./vendor/bokeh/bokeh-api-2.4.1.min.js\"></script><script src=\"./vendor/bokeh/bokeh-gl-2.4.1.min.js\"></script><script src=\"./vendor/bokeh/bokeh-mathjax-2.4.1.min.js\"></script><link href=\"./static/css/5.099fba4a.chunk.css\" rel=\"stylesheet\"><link href=\"./static/css/main.b46f6fce.chunk.css\" rel=\"stylesheet\"></head><body><noscript>You need to enable JavaScript to run this app.</noscript><div id=\"root\"></div><script>!function(e){function t(t){for(var n,c,a=t[0],d=t[1],u=t[2],i=0,s=[];i<a.length;i++)c=a[i],Object.prototype.hasOwnProperty.call(f,c)&&f[c]&&s.push(f[c][0]),f[c]=0;for(n in d)Object.prototype.hasOwnProperty.call(d,n)&&(e[n]=d[n]);for(l&&l(t);s.length;)s.shift()();return o.push.apply(o,u||[]),r()}function r(){for(var e,t=0;t<o.length;t++){for(var r=o[t],n=!0,c=1;c<r.length;c++){var d=r[c];0!==f[d]&&(n=!1)}n&&(o.splice(t--,1),e=a(a.s=r[0]))}return e}var n={},c={4:0},f={4:0},o=[];function a(t){if(n[t])return n[t].exports;var r=n[t]={i:t,l:!1,exports:{}};return e[t].call(r.exports,r,r.exports,a),r.l=!0,r.exports}a.e=function(e){var t=[];c[e]?t.push(c[e]):0!==c[e]&&{6:1}[e]&&t.push(c[e]=new Promise((function(t,r){for(var n=\"static/css/\"+({}[e]||e)+\".\"+{0:\"31d6cfe0\",1:\"31d6cfe0\",2:\"31d6cfe0\",6:\"41c38bce\",7:\"31d6cfe0\",8:\"31d6cfe0\",9:\"31d6cfe0\",10:\"31d6cfe0\",11:\"31d6cfe0\",12:\"31d6cfe0\",13:\"31d6cfe0\",14:\"31d6cfe0\",15:\"31d6cfe0\",16:\"31d6cfe0\",17:\"31d6cfe0\",18:\"31d6cfe0\",19:\"31d6cfe0\",20:\"31d6cfe0\",21:\"31d6cfe0\",22:\"31d6cfe0\",23:\"31d6cfe0\",24:\"31d6cfe0\",25:\"31d6cfe0\",26:\"31d6cfe0\",27:\"31d6cfe0\",28:\"31d6cfe0\",29:\"31d6cfe0\",30:\"31d6cfe0\",31:\"31d6cfe0\",32:\"31d6cfe0\",33:\"31d6cfe0\",34:\"31d6cfe0\",35:\"31d6cfe0\",36:\"31d6cfe0\",37:\"31d6cfe0\",38:\"31d6cfe0\",39:\"31d6cfe0\",40:\"31d6cfe0\"}[e]+\".chunk.css\",f=a.p+n,o=document.getElementsByTagName(\"link\"),d=0;d<o.length;d++){var u=(l=o[d]).getAttribute(\"data-href\")||l.getAttribute(\"href\");if(\"stylesheet\"===l.rel&&(u===n||u===f))return t()}var i=document.getElementsByTagName(\"style\");for(d=0;d<i.length;d++){var l;if((u=(l=i[d]).getAttribute(\"data-href\"))===n||u===f)return t()}var s=document.createElement(\"link\");s.rel=\"stylesheet\",s.type=\"text/css\",s.onload=t,s.onerror=function(t){var n=t&&t.target&&t.target.src||f,o=new Error(\"Loading CSS chunk \"+e+\" failed.\\n(\"+n+\")\");o.code=\"CSS_CHUNK_LOAD_FAILED\",o.request=n,delete c[e],s.parentNode.removeChild(s),r(o)},s.href=f,document.getElementsByTagName(\"head\")[0].appendChild(s)})).then((function(){c[e]=0})));var r=f[e];if(0!==r)if(r)t.push(r[2]);else{var n=new Promise((function(t,n){r=f[e]=[t,n]}));t.push(r[2]=n);var o,d=document.createElement(\"script\");d.charset=\"utf-8\",d.timeout=120,a.nc&&d.setAttribute(\"nonce\",a.nc),d.src=function(e){return a.p+\"static/js/\"+({}[e]||e)+\".\"+{0:\"2114760d\",1:\"4d16f7c9\",2:\"59375263\",6:\"cd481a8b\",7:\"2295a87a\",8:\"bc1949a7\",9:\"ec07acc2\",10:\"27fd1a5d\",11:\"157e6548\",12:\"6e54efd1\",13:\"2341fbda\",14:\"5dd3949a\",15:\"b14c9559\",16:\"a6776398\",17:\"10d4a09c\",18:\"091827b0\",19:\"df4978eb\",20:\"f138e469\",21:\"3227321c\",22:\"4fc1b570\",23:\"c81e5a07\",24:\"973b89ff\",25:\"6977f666\",26:\"1ab396e4\",27:\"41f14cf7\",28:\"cf697d8a\",29:\"968fbe3e\",30:\"2c4b5456\",31:\"63a95f8b\",32:\"d6579a8f\",33:\"6142a934\",34:\"f27f2a89\",35:\"48acc41d\",36:\"4e75ce57\",37:\"18fcd3cd\",38:\"83a166c3\",39:\"6e492d60\",40:\"2a83e23c\"}[e]+\".chunk.js\"}(e);var u=new Error;o=function(t){d.onerror=d.onload=null,clearTimeout(i);var r=f[e];if(0!==r){if(r){var n=t&&(\"load\"===t.type?\"missing\":t.type),c=t&&t.target&&t.target.src;u.message=\"Loading chunk \"+e+\" failed.\\n(\"+n+\": \"+c+\")\",u.name=\"ChunkLoadError\",u.type=n,u.request=c,r[1](u)}f[e]=void 0}};var i=setTimeout((function(){o({type:\"timeout\",target:d})}),12e4);d.onerror=d.onload=o,document.head.appendChild(d)}return Promise.all(t)},a.m=e,a.c=n,a.d=function(e,t,r){a.o(e,t)||Object.defineProperty(e,t,{enumerable:!0,get:r})},a.r=function(e){\"undefined\"!=typeof Symbol&&Symbol.toStringTag&&Object.defineProperty(e,Symbol.toStringTag,{value:\"Module\"}),Object.defineProperty(e,\"__esModule\",{value:!0})},a.t=function(e,t){if(1&t&&(e=a(e)),8&t)return e;if(4&t&&\"object\"==typeof e&&e&&e.__esModule)return e;var r=Object.create(null);if(a.r(r),Object.defineProperty(r,\"default\",{enumerable:!0,value:e}),2&t&&\"string\"!=typeof e)for(var n in e)a.d(r,n,function(t){return e[t]}.bind(null,n));return r},a.n=function(e){var t=e&&e.__esModule?function(){return e.default}:function(){return e};return a.d(t,\"a\",t),t},a.o=function(e,t){return Object.prototype.hasOwnProperty.call(e,t)},a.p=\"./\",a.oe=function(e){throw console.error(e),e};var d=this[\"webpackJsonpstreamlit-browser\"]=this[\"webpackJsonpstreamlit-browser\"]||[],u=d.push.bind(d);d.push=t,d=d.slice();for(var i=0;i<d.length;i++)t(d[i]);var l=u;r()}([])</script><script src=\"./static/js/5.53d5cfe3.chunk.js\"></script><script src=\"./static/js/main.c08d602e.chunk.js\"></script></body></html>"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FY1PHACAc2z4","executionInfo":{"status":"ok","timestamp":1639713236954,"user_tz":300,"elapsed":6622,"user":{"displayName":"Sumedha Sirikonda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13604935234152853023"}},"outputId":"0a920767-4488-4fb7-82f7-9107b4337650"},"source":["!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip && unzip ngrok-stable-linux-amd64.zip"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--2021-12-17 03:53:49--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n","Resolving bin.equinox.io (bin.equinox.io)... 54.237.133.81, 18.205.222.128, 54.161.241.46, ...\n","Connecting to bin.equinox.io (bin.equinox.io)|54.237.133.81|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 13832437 (13M) [application/octet-stream]\n","Saving to: â€˜ngrok-stable-linux-amd64.zip.7â€™\n","\n","ngrok-stable-linux- 100%[===================>]  13.19M  12.7MB/s    in 1.0s    \n","\n","2021-12-17 03:53:50 (12.7 MB/s) - â€˜ngrok-stable-linux-amd64.zip.7â€™ saved [13832437/13832437]\n","\n","Archive:  ngrok-stable-linux-amd64.zip\n","replace ngrok? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n","  inflating: ngrok                   \n"]}]},{"cell_type":"code","metadata":{"id":"21bynfFLc7FM"},"source":["%%bash --bg\n","./ngrok authtoken 22ChX1g0I3fhvzJloTJSPsfUi4C_7ZiUx8V7LhRJKYy3s1BPN\n","./ngrok http 172.28.0.2:8501 > ngrok.log 2>&1\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"paeUtIHJFduP"},"source":["!tail ngrok.log"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# !top"],"metadata":{"id":"r7r9-x1E8NLZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XWiI1lwlnhAU"},"source":["%%bash --bg\n","./ngrok help"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MxfbAYkOFR3Q"},"source":["%%capture\n","#https://stedolan.github.io/jq/tutorial/\n","\n","!apt-get install jq"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9ajf8F3fFTH1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1639713265907,"user_tz":300,"elapsed":254,"user":{"displayName":"Sumedha Sirikonda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13604935234152853023"}},"outputId":"5839ea34-6db5-4939-9fcb-1279c988490d"},"source":["!curl -s http://localhost:4040/api/tunnels | jq \".tunnels[0].public_url\""],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[0;32m\"https://2923-35-230-110-239.ngrok.io\"\u001b[0m\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"j_OASVqPDm6L"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"vLd0IjbiDm7z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"vKCamE-JDnHO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"q3r6fBHQDnX7"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ruLQTUlNFm8G"},"source":["!jq '.[0] | {message: .commit.message, name: .commit.committer.name}'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2M9sQ-5HFm-K"},"source":["%%bash --bg\n","# netstat -ln | grep 8501\n","netstat -tlpen | grep 4040"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kH0sFfGFFnBL"},"source":["%%capture\n","!sudo netstat -tulpn\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QJz3MRdDFnC5"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9bYwSi6PgCqo"},"source":[""],"execution_count":null,"outputs":[]}]}